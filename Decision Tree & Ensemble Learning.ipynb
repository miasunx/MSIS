{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bYyOjdzhs1T"
   },
   "source": [
    "# Decision Tree & Ensemble Learning\n",
    "\n",
    "Classification And Regression Trees (CART for short) is a term introduced by [Leo Breiman](https://en.wikipedia.org/wiki/Leo_Breiman) to refer to Decision Tree algorithms that can be used for classification or regression predictive modeling problems.\n",
    "\n",
    "In this lab assignment, you will implement various ways to calculate impurity which is used to split data in constructing the decision trees and apply the Decision Tree and ensemble learning algorithms to solve two real-world problems: a classification one and a regression one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsJh8RbLhs1V"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# make this notebook's output stable across runs\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wdJsuTqhs1a"
   },
   "source": [
    "## Gini impurity and Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzfYaZ-hhs1b"
   },
   "source": [
    "#### Gini impurity\n",
    "\n",
    "The CART algorithm recursively splits the training set into two subsets using a single feature k and a threshold $t_k$. The best feature and threshold are chosen to produce the purest subsets weighted by their size. **Gini impurity** measures the impurity of the data points in a set and is used to evaluate how good a split is when the CART algorithm searches for the best pair of feature and the threshold.\n",
    "\n",
    "To compute Gini impurity for a set of items with J classes, suppose $i \\in \\{1, 2, \\dots, J\\}$ and let $p_i$ be the fraction of items labeled with class i in the set.\n",
    "\\begin{align}\n",
    "I(p) = 1 - \\sum_{i=1}^J p_i^2\n",
    "\\end{align}\n",
    "\n",
    "The following function calculates the gini impurity for a given set of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNexBvnehs1c"
   },
   "outputs": [],
   "source": [
    "def gini_impurity(x):\n",
    "    \"\"\"\n",
    "    This function calculate the Gini impurity for a given set of data points.\n",
    "\n",
    "    Args:\n",
    "    x: a numpy ndarray\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    probabilities = counts / sum(counts)\n",
    "    gini = 1 - sum([p*p for p in probabilities])\n",
    "\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmZaWVMxhs1g"
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(0, gini_impurity(np.array([1, 1, 1])))\n",
    "np.testing.assert_equal(0.5, gini_impurity(np.array([1, 0, 1, 0])))\n",
    "np.testing.assert_equal(3/4, gini_impurity(np.array(['a', 'b', 'c', 'd'])))\n",
    "np.testing.assert_almost_equal(2.0/3, gini_impurity(np.array([1, 2, 3, 1, 2, 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bSsc9tL7hs1k"
   },
   "source": [
    "#### Entropy\n",
    "\n",
    "Another popular measure of impurity is called **entropy**, which measures the average information content of a message. Entropy is zero when all messages are identical. When it applied to CART, a set's entropy is zero when it contains instances of only one class. Entropy is calculated as follows:\n",
    "\\begin{align}\n",
    "I(p) = - \\sum_{i=1}^J p_i log_2{p_i}\n",
    "\\end{align}\n",
    "\n",
    "<span style=\"color:orange\">**Question 1: In this exercise, you will implement the entropy function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy as ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wr8caP2Xhs1l"
   },
   "outputs": [],
   "source": [
    "def entropy(x):\n",
    "    \"\"\"\n",
    "    TODO: This function calculate the entropy of an array.\n",
    "\n",
    "    Args:\n",
    "    x: a numpy ndarray\n",
    "    \"\"\"\n",
    "    value, counts = np.unique(x, return_counts = True)\n",
    "    e = ent(counts, base = 2)\n",
    "\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpOdGMWDhs1p"
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(0, entropy(np.array([1, 1, 1])))\n",
    "np.testing.assert_equal(1.0, entropy(np.array([1, 0, 1, 0])))\n",
    "np.testing.assert_equal(2.0, entropy(np.array(['a', 'b', 'c', 'd'])))\n",
    "np.testing.assert_almost_equal(1.58496, entropy(np.array([1, 2, 3, 1, 2, 3])), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qX1XT12hs1t"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZGblkNkhs2g"
   },
   "source": [
    "## Iris dataset\n",
    "\n",
    "The Iris data set contains the morphologic variation of Iris flowers of three related species (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each observation (see image below):\n",
    "- Sepal.Length: sepal length in centimeters.\n",
    "- Sepal.Width: sepal width in centimeters.\n",
    "- Petal.Length: petal length in centimeters.\n",
    "- Petal.Width: petal width in centimeters.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\" style=\"width:250px\"></td>\n",
    "    <td><img src=\"https://www.math.umd.edu/~petersd/666/html/iris_with_labels.jpg\" width=\"250px\"></td>\n",
    "    <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\" width=\"250px\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Iris setosa</td>\n",
    "    <td>Iris versicolor</td>\n",
    "    <td>Iris virginica</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BfuNcWVhs2h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa        34\n",
      "Iris-versicolor    32\n",
      "Iris-virginica     39\n",
      "Name: species, dtype: int64\n",
      "Iris-setosa        16\n",
      "Iris-versicolor    18\n",
      "Iris-virginica     11\n",
      "Name: species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load the iris train and test data from CSV files\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/zariable/data/master/iris_train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/zariable/data/master/iris_test.csv')\n",
    "\n",
    "train_x = train.iloc[:,0:4]\n",
    "train_y = train.iloc[:,4]\n",
    "\n",
    "test_x = test.iloc[:,0:4]\n",
    "test_y = test.iloc[:,4]\n",
    "\n",
    "# print the number of instances in each class\n",
    "print(train_y.value_counts().sort_index())\n",
    "print(test_y.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpe8jv7Qhs2f"
   },
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "<span style=\"color:orange\">**In this exercise, we will apply the Decision Tree classifier to classify the Iris flower data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8JwQoOdPhs2j"
   },
   "source": [
    "#### Train and visualize a simple Decision Tree\n",
    "\n",
    "<span style=\"color:orange\">**Question 2: create a decision tree with max_depth of 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQzTTFGlhs2k",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: read the scikit-learn doc on DecisionTreeClassifier and train a Decision Tree with max depth of 2\n",
    "dtc = DecisionTreeClassifier(max_depth = 2)\n",
    "\n",
    "dtc.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tn25MVpchs2n"
   },
   "source": [
    "Now let's visualize the decision tree we just trained on the iris dataset and see how it makes predictions. Note that if the following code does not work for you because the graphviz is missing, do not worry about it and you should still be able to move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of feature_names, 8 does not match number of features, 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-6a211af718c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_characters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             precision=precision)\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mexporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, decision_tree)\u001b[0m\n\u001b[1;32m    399\u001b[0m                                  \u001b[0;34m\"does not match number of features, %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                                  % (len(self.feature_names),\n\u001b[0;32m--> 401\u001b[0;31m                                     decision_tree.n_features_))\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;31m# each part writes to out_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of feature_names, 8 does not match number of features, 4"
     ]
    }
   ],
   "source": [
    "from six import StringIO \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "feature_names = train_x.columns\n",
    "class_names = train_y.unique()\n",
    "class_names.sort()\n",
    "export_graphviz(dtc, out_file=dot_data, feature_names=feature_names, class_names=class_names, filled=True, rounded=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgqeLw6Lhs2t"
   },
   "source": [
    "Decision trees are easy to inteprete and is often referred to as *whitebox* machine learning algorithm. Let's see how this decision tree represented above makes predictions. Suppose you find an iris flower and want to classify it into setosa, versicolor or virginica. You start at the root node (the very top node in the tree). In this node, we check if the flower's patel length is smaller than or equal to 2.35 cm. If it is, we move to the left child and predict setosa to be its class. Otherwise, we move to the right child node. Then similarly we check if the petal length is smaller than or equal to 4.95 cm. If it is, we move to its left child node and predict versicolor to be its class. Otherwise, we move to its right child and predict virginica to be its class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W94pWMvIhs2t"
   },
   "source": [
    "#### Prediction with Decision tree\n",
    "\n",
    "With this simple decision tree above, we can apply it to make predictions on the test dataset and evaluate its performance.\n",
    "\n",
    "<span style=\"color:orange\">**Question 3: make prediction using the trained decision tree model on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugRPudSThs2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.9111111111111111\n",
      "model confusion matrix:\n",
      " [[16  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  3  8]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: use the trained decision tree model to make predictions on the test data and evaluate the model performance.\n",
    "train_z = dtc.predict(train_x)\n",
    "train_z_prob = dtc.predict_proba(train_x)[:,1]\n",
    "\n",
    "test_z = dtc.predict(test_x)\n",
    "test_z_prob = dtc.predict_proba(test_x)[:,1]\n",
    "\n",
    "print(\"model accuracy: {}\".format(accuracy_score(test_y, test_z)))\n",
    "print(\"model confusion matrix:\\n {}\".format(confusion_matrix(test_y, test_z, labels=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMzcZjQQhs2x"
   },
   "source": [
    "#### Hyper-parameters\n",
    "\n",
    "Hyper-parameter controls the complexity of the decision tree model. For example, the deeper the tree is, the more complex patterns the model will be able to capture. In this exercise, we train the decision trees with increasing number of maximum depth and plot its performance. We should see the accuracy of the training data increase as the tree grows deeper, but the accuracy on the test data might not as the model will eventually start to overfit and does not generalize well on the unseen test data.\n",
    "\n",
    "<span style=\"color:orange\">**Question 4: for each value of max_depth, we train a decision tree model and evaluate its accuracy on both train and test data, and plot both accuracies in the figure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uw23r_MXhs2x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy on train set: [0.7, 0.96, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "model accuracy on test set: [0.6, 0.91, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98]\n"
     ]
    }
   ],
   "source": [
    "# TODO: train the decision tree model with various max_depth, make predictions and evaluate on both train and test data.\n",
    "\n",
    "max_depth= [1,2,3,4,5,6,7,8]\n",
    "train_acu = []\n",
    "test_acu = []\n",
    "\n",
    "for depth in max_depth: \n",
    "    dtc = DecisionTreeClassifier(max_depth= depth )\n",
    "    dtc.fit(train_x, train_y)\n",
    "    train_z = dtc.predict(train_x)\n",
    "    test_z = dtc.predict(test_x)\n",
    "    train_acu.append(accuracy_score(train_y, train_z).round(2))\n",
    "    test_acu.append(accuracy_score(test_y, test_z).round(2))\n",
    "\n",
    "print(\"model accuracy on train set: {}\".format(train_acu))\n",
    "print(\"model accuracy on test set: {}\".format(test_acu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2iaLr1ufhs20"
   },
   "source": [
    "#### Fine-tune the decision tree classifier\n",
    "\n",
    "Decision tree is a very powerful model with very few assumptions about the incoming training data (unlike linear models, which assume the data linear), however, it is more likely to overfit the data and won't generalize well to unseen data. To void overfitting, we need to restrict the decision tree's freedom during training via regularization (e.g. max_depth, min_sample_split, max_leaf_nodes and etc.).\n",
    "\n",
    "To fine-tune the model and combat overfitting, use grid search with cross-validation (with the help of the GridSearchCV class) to find the best hyper-parameter settings for the DecisionTreeClassifier. In particular, we would like to fine-tune the following hyper-parameters:\n",
    "- **criteria**: this defines how we measure the quality of a split. we can choose either \"gini\" for the Gini impurity or \"entropy\" for the information gain.\n",
    "- **max_depth**: the maximum depth of the tree. This indicates how deep the tree can be. The deeper the tree, the more splits it has and it captures more information about the data. But meanwhile, deeper trees are more likely to overfit the data. For this practice, we will choose from {1, 2, 3} given there are only 4 features in the iris dataset.\n",
    "- **min_samples_split**: This value represents the minimum number of samples required to split an internal node. The smaller this value is, the deeper the tree will grow, thus more likely to overfit. On the other hand, if the value is really large (the size of the training data in the extreme case), the tree will be very shallow and could suffer from underfit. In this practice, we choose from {0.01, 0.05, 0.1, 0.2}.\n",
    "\n",
    "<span style=\"color:orange\">**Question 5: Use grid search with 3-fold cross-validation to fine-tune the decision tree model and output the best hyper-parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fuI5TWkhs21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is 0.9619047619047619\n",
      "The best hyper parameter setting is {'max_depth': 3, 'min_samples_split': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunweijie/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO: fine-tune the model, use grid search with 3-fold cross-validation.\n",
    "parameters = {\n",
    "    \"max_depth\": [1, 2, 3], \n",
    "    \"min_samples_split\": [0.01, 0.05, 0.1,0.2]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(dtc, parameters, cv=3)\n",
    "grid.fit(train_x, train_y)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"The best score is {}\".format(grid.best_score_))\n",
    "print(\"The best hyper parameter setting is {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXeHA4TThs24"
   },
   "source": [
    "#### Prediction and Evaluation\n",
    "\n",
    "Now we have a fine-tuned decision tree classifier based on the training data, let's apply this model to make predictions on the test data and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzGEUWFPhs24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy: 0.9777777777777777\n",
      "model confusion matrix:\n",
      " [[16  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "grid.predict(test_x)\n",
    "\n",
    "print(\"model accuracy: {}\".format(accuracy_score(test_y, test_z)))\n",
    "print(\"model confusion matrix:\\n {}\".format(confusion_matrix(test_y, test_z, labels=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLrLCXpbIHI2"
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "**Question 6: Apply Random Forest together with Gridsearch to the Iris dataset and evaluate its accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is 0.9619047619047619\n",
      "The best hyper parameter setting is {'max_depth': 3, 'min_samples_split': 0.01, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "def gridsearch(estimator, parameters, train_x, train_y):\n",
    "    grid = GridSearchCV(estimator, parameters)\n",
    "\n",
    "    grid.fit(train_x, train_y)\n",
    "    \n",
    "# summarize the results of the grid search\n",
    "print(\"The best score is {}\".format(rfc_grid.best_score_))\n",
    "print(\"The best hyper parameter setting is {}\".format(rfc_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UTzDdKnoIDM1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunweijie/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/sunweijie/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "### TODO \n",
    "rf_parameters = {'criterion': ('gini', 'entropy'),\n",
    "                'max_depth': [1, 2, 3],\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'min_samples_split':[0.01, 0.05, 0.1, 0.2]}\n",
    "\n",
    "gridsearch(RandomForestClassifier(), rf_parameters, train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKgNC7kzIWNC"
   },
   "source": [
    "### Adaboost\n",
    "\n",
    "**Question 7: Apply Adaboost together with Gridsearch to the Iris dataset and evaluate its accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDcP-xy_IXFF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is 0.9523809523809523\n",
      "The best hyper parameter setting is {'learning_rate': 0.01, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "### TODO \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": [20, 40,60],\n",
    "    \"learning_rate\": [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "adaboost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), random_state=0)\n",
    "adaboost_grid = GridSearchCV(adaboost, parameters, cv=3)\n",
    "adaboost_grid.fit(train_x, train_y)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"The best score is {}\".format(adaboost_grid.best_score_))\n",
    "print(\"The best hyper parameter setting is {}\".format(adaboost_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpZFN60NIWdK"
   },
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "**Question 8: Apply Boosting together with Gridsearch to the Iris dataset and evaluate its accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmRcvEkSIXrR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is 0.9619047619047619\n",
      "The best hyper parameter setting is {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 2, 'min_samples_split': 0.05, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunweijie/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "### TODO \n",
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"min_samples_split\": [0.05, 0.1, 0.2],\n",
    "    \"max_depth\":[2, 4],\n",
    "    \"n_estimators\":[100]\n",
    "}\n",
    "\n",
    "gbc_grid = GridSearchCV(GradientBoostingClassifier(), parameters, cv=3, n_jobs=-1)\n",
    "gbc_grid.fit(train_x, train_y)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"The best score is {}\".format(gbc_grid.best_score_))\n",
    "print(\"The best hyper parameter setting is {}\".format(gbc_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aTlPSt2Uhs26"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oyoZxHnxHknE"
   },
   "source": [
    "**BONUS POINT: we will apply the supervised learning models we learnt so far to predict the California housing prices.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3odrweXdhs28"
   },
   "source": [
    "## California Housing Dataset\n",
    "\n",
    "The California Housing dataset appeared in a 1997 paper titled Sparse Spatial Autoregressions by Pace, R. Kelley and Ronald Barry, published in the Statistics and Probability Letters journal. They built it using the 1990 California census data. It contains one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zXK2RFshs29"
   },
   "outputs": [],
   "source": [
    "# Load train and test data from CSV files.\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/zariable/data/master/housing_train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/zariable/data/master/housing_test.csv')\n",
    "\n",
    "train_x = train.iloc[:,0:8]\n",
    "train_y = train.iloc[:,8]\n",
    "\n",
    "test_x = test.iloc[:,0:8]\n",
    "test_y = test.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-Xv_wdQJob8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-119.79</td>\n",
       "      <td>36.73</td>\n",
       "      <td>52.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.9750</td>\n",
       "      <td>47500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-122.21</td>\n",
       "      <td>37.77</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2.2604</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-118.04</td>\n",
       "      <td>33.87</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>6.2990</td>\n",
       "      <td>285800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-118.28</td>\n",
       "      <td>34.06</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2518.0</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.7199</td>\n",
       "      <td>175000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-119.81</td>\n",
       "      <td>36.73</td>\n",
       "      <td>50.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.2206</td>\n",
       "      <td>59200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -119.79     36.73                52.0        112.0            28.0   \n",
       "1    -122.21     37.77                43.0       1017.0           328.0   \n",
       "2    -118.04     33.87                17.0       2358.0           396.0   \n",
       "3    -118.28     34.06                17.0       2518.0          1196.0   \n",
       "4    -119.81     36.73                50.0        772.0           194.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0       193.0        40.0         1.9750             47500.0  \n",
       "1       836.0       277.0         2.2604            100000.0  \n",
       "2      1387.0       364.0         6.2990            285800.0  \n",
       "3      3051.0      1000.0         1.7199            175000.0  \n",
       "4       606.0       167.0         2.2206             59200.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14448 entries, 0 to 14447\n",
      "Data columns (total 9 columns):\n",
      "longitude             14448 non-null float64\n",
      "latitude              14448 non-null float64\n",
      "housing_median_age    14448 non-null float64\n",
      "total_rooms           14448 non-null float64\n",
      "total_bedrooms        14448 non-null float64\n",
      "population            14448 non-null float64\n",
      "households            14448 non-null float64\n",
      "median_income         14448 non-null float64\n",
      "median_house_value    14448 non-null float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1016.0 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitclass(classifier, train_x, train_y, test_x, test_y):\n",
    "    classifier.fit(train_x, train_y)\n",
    "    \n",
    "    print(classifier.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6284911999019254\n",
      "0.6463678940824277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunweijie/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7909464369665637\n"
     ]
    }
   ],
   "source": [
    "fitclass(LinearRegression(), train_x, train_y, test_x, test_y)\n",
    "fitclass(DecisionTreeRegressor(), train_x, train_y, test_x, test_y)\n",
    "fitclass(RandomForestRegressor(), train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-zitGTxhs3E"
   },
   "source": [
    "### End of Assignment 2\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bSsc9tL7hs1k"
   ],
   "name": "MSIS522-Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
